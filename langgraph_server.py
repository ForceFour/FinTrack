"""
LangGraph Server for Studio Visualization
This creates a local server that LangGraph Studio can connect to
"""
import os
import sys
from pathlib import Path
import uuid

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv()

from langgraph.graph import StateGraph, END
from typing import Dict, Any, List, TypedDict
from datetime import datetime

# Import our detailed workflow
class DetailedIngestionState(TypedDict):
    """State for detailed ingestion workflow"""
    input_text: str
    groq_extraction: Dict[str, Any]
    confidence_score: float
    extracted_amount: str
    extracted_merchant: str
    extracted_date: str
    preprocessed_transactions: List[Dict[str, Any]]
    validation_results: Dict[str, Any]
    final_output: Dict[str, Any]
    metadata: Dict[str, Any]

def receive_input(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 1: Receive and prepare natural language input"""
    print(f"ğŸ¯ RECEIVING: Processing natural language input")
    state["metadata"] = {
        "step": "input_received",
        "timestamp": datetime.now().isoformat(),
        "input_length": len(state["input_text"])
    }
    return state

def groq_extraction(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 2: Use Groq LLM to extract transaction data"""
    print(f"ğŸ¤– GROQ LLM: Extracting transaction details with Groq")
    
    # Simulate what the Groq LLM extraction does
    state["groq_extraction"] = {
        "raw_response": "Amount: $4.50, Merchant: Starbucks, Time: this morning",
        "extraction_method": "LLM",
        "model_used": "groq-llama"
    }
    state["metadata"]["groq_processing"] = True
    
    return state

def confidence_evaluation(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 3: Evaluate extraction confidence"""
    print(f"ğŸ“Š CONFIDENCE: Evaluating extraction confidence")
    
    # Simulate confidence calculation
    state["confidence_score"] = 0.90
    state["metadata"]["confidence_threshold"] = 0.70
    state["metadata"]["confidence_met"] = True
    
    return state

def amount_processing(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 4: Process and normalize amount"""
    print(f"ğŸ’° AMOUNT: Processing transaction amount")
    
    state["extracted_amount"] = "$4.50"
    state["metadata"]["amount_normalized"] = 4.50
    state["metadata"]["currency"] = "USD"
    
    return state

def merchant_extraction(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 5: Extract and standardize merchant name"""
    print(f"ğŸª MERCHANT: Extracting merchant information")
    
    state["extracted_merchant"] = "Starbucks"
    state["metadata"]["merchant_standardized"] = "Starbucks Corporation"
    state["metadata"]["merchant_category"] = "Coffee Shop"
    
    return state

def date_normalization(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 6: Normalize date information"""
    print(f"ğŸ“… DATE: Normalizing date and time")
    
    state["extracted_date"] = datetime.now().strftime("%Y-%m-%d")
    state["metadata"]["date_source"] = "inferred_today"
    state["metadata"]["time_reference"] = "this morning"
    
    return state

def data_preprocessing(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 7: Apply data preprocessing pipeline"""
    print(f"âš™ï¸ PREPROCESSING: Applying data preprocessing pipeline")
    
    # Simulate preprocessing
    preprocessed_txn = {
        "id": f"txn_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        "amount": 4.50,
        "merchant": "Starbucks",
        "date": state["extracted_date"],
        "category": "food_dining",
        "description_cleaned": "Coffee purchase at Starbucks"
    }
    
    state["preprocessed_transactions"] = [preprocessed_txn]
    state["metadata"]["preprocessing_complete"] = True
    
    return state

def validation_output(state: DetailedIngestionState) -> DetailedIngestionState:
    """Step 8: Validate and prepare final output"""
    print(f"âœ… VALIDATION: Validating and finalizing output")
    
    state["validation_results"] = {
        "amount_valid": True,
        "merchant_valid": True,
        "date_valid": True,
        "overall_valid": True
    }
    
    state["final_output"] = {
        "transactions_processed": len(state["preprocessed_transactions"]),
        "confidence": state["confidence_score"],
        "status": "completed"
    }
    
    return state

# Build the workflow
def create_ingestion_workflow():
    """Create the ingestion workflow for Studio"""
    workflow = StateGraph(DetailedIngestionState)
    
    # Add nodes
    workflow.add_node("ğŸ¯ Receive NL Input", receive_input)
    workflow.add_node("ğŸ¤– Groq LLM Extraction", groq_extraction)
    workflow.add_node("ğŸ“Š Confidence Evaluation", confidence_evaluation)
    workflow.add_node("ğŸ’° Amount Processing", amount_processing)
    workflow.add_node("ğŸª Merchant Extraction", merchant_extraction)
    workflow.add_node("ğŸ“… Date Normalization", date_normalization)
    workflow.add_node("âš™ï¸ Data Preprocessing", data_preprocessing)
    workflow.add_node("âœ… Validation & Output", validation_output)
    
    # Define edges
    workflow.add_edge("ğŸ¯ Receive NL Input", "ğŸ¤– Groq LLM Extraction")
    workflow.add_edge("ğŸ¤– Groq LLM Extraction", "ğŸ“Š Confidence Evaluation")
    workflow.add_edge("ğŸ“Š Confidence Evaluation", "ğŸ’° Amount Processing")
    workflow.add_edge("ğŸ’° Amount Processing", "ğŸª Merchant Extraction")
    workflow.add_edge("ğŸª Merchant Extraction", "ğŸ“… Date Normalization")
    workflow.add_edge("ğŸ“… Date Normalization", "âš™ï¸ Data Preprocessing")
    workflow.add_edge("âš™ï¸ Data Preprocessing", "âœ… Validation & Output")
    workflow.add_edge("âœ… Validation & Output", END)
    
    # Set entry point
    workflow.set_entry_point("ğŸ¯ Receive NL Input")
    
    return workflow

# Create the compiled app without custom checkpointer for LangGraph Studio
workflow = create_ingestion_workflow()
# Remove the custom checkpointer - LangGraph API handles persistence automatically
app = workflow.compile()

if __name__ == "__main__":
    print("ğŸš€ LangGraph Server for Studio Visualization")
    print("=" * 50)
    print("ğŸ“Š Workflow created with 8 nodes:")
    print("   1. ğŸ¯ Receive NL Input")
    print("   2. ğŸ¤– Groq LLM Extraction") 
    print("   3. ğŸ“Š Confidence Evaluation")
    print("   4. ğŸ’° Amount Processing")
    print("   5. ğŸª Merchant Extraction")
    print("   6. ğŸ“… Date Normalization")
    print("   7. âš™ï¸ Data Preprocessing")
    print("   8. âœ… Validation & Output")
    print("\nâœ… Ready for LangGraph Studio!")
    print("ğŸŒ Use this file with LangGraph Studio to visualize the workflow")
